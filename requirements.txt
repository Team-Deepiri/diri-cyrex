fastapi==0.112.2
uvicorn[standard]==0.30.6
pydantic==2.8.2
openai==1.43.0
python-dotenv==1.0.1
httpx==0.27.2
pytest==8.3.2
pytest-asyncio==0.23.5
pytest-cov==4.1.0
structlog==24.1.0
python-json-logger==2.0.7
prometheus-client==0.20.0
redis[hiredis]>=5.0.1  # Includes hiredis for better async performance
pydantic-settings==2.2.1

# AI Training Dependencies
torch>=2.0.0
transformers>=4.30.0
datasets>=2.14.0
accelerate>=0.20.0
deepspeed>=0.12.0  # For distributed training
mlflow>=2.7.0
wandb>=0.15.0
jupyter>=1.0.0
notebook>=6.5.0
scikit-learn>=1.3.0
numpy>=1.24.0
pandas>=2.0.0

# New AI Service Dependencies
peft>=0.7.0  # For LoRA adapters
bitsandbytes>=0.41.0  # For quantization
gymnasium>=0.29.0  # For RL environment
stable-baselines3>=2.2.0  # For RL algorithms (optional)

# Vector Database Dependencies
pymilvus>=2.3.0  # For Milvus vector database
pinecone-client>=3.0.0  # For Pinecone (optional)
weaviate-client>=4.0.0  # For Weaviate (optional)

# Time-Series Analytics
influxdb-client>=1.38.0  # For InfluxDB

# MLOps Dependencies
kubernetes>=28.1.0  # For Kubernetes deployment

# Additional ML Libraries
optuna>=3.5.0  # For hyperparameter optimization (optional)
hyperopt>=0.2.7  # For hyperparameter optimization (optional)
tensorboard>=2.15.0  # For visualization (optional)

# Sentence Transformers for embeddings
sentence-transformers>=2.2.0

# LangChain for AI orchestration and RAG
langchain>=0.1.0
langchain-openai>=0.0.5
langchain-community>=0.0.20
langchain-core>=0.1.0
langchain-chroma>=0.1.0
langchain-milvus>=0.1.0
langchain-text-splitters>=0.0.1
langsmith>=0.0.60  # Optional: for LangSmith monitoring and debugging

# Local LLM Support (Cost-effective alternatives to OpenAI)
ollama>=0.1.0  # Ollama API client for local models
llama-cpp-python>=0.2.0  # llama.cpp bindings (optional, for direct model loading)
# Note: Install llama-cpp-python separately with: pip install llama-cpp-python
# For GPU support: CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python
# For CPU only: pip install llama-cpp-python
